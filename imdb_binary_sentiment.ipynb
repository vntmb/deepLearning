{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# import dataset\nfrom keras.datasets import imdb\n\n# Deep learning modules\nfrom keras import layers, losses, metrics, models, optimizers\n\n# import plotting libs\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ea8ebef627ce464c7c320108111eef50762288e4"
      },
      "cell_type": "code",
      "source": "word_index = imdb.get_word_index()\nreverse_word_index = dict(\n    [(value, key) for (key, value) in word_index.items()])\ndecoded_review = ' '.join(\n    [reverse_word_index.get(i - 3, '?') for i in train_data[0]])\n\nprint(decoded_review)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f8293da502744f415a3422dea5852022fc973176"
      },
      "cell_type": "code",
      "source": "def vectorize_sequences(sequences, dimension=10000):\n    results = np.zeros((len(sequences), dimension))\n    for i, sequence in enumerate(sequences):\n        results[i, sequence] = 1.\n    return results\n\nx_train = vectorize_sequences(train_data)\nx_test = vectorize_sequences(test_data)\n\ny_train = np.asarray(train_labels).astype('float32')\ny_test = np.asarray(test_labels).astype('float32')\n\nprint(x_train[0])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f16ffffc506b5d3e2b9b75023d4f207794110cb4"
      },
      "cell_type": "code",
      "source": "# Defining nn model\nmodel = models.Sequential()\nmodel.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\n# compiling the model\nmodel.compile(optimizer=optimizers.RMSprop(lr=0.001),\n             loss=losses.binary_crossentropy,\n             metrics=[metrics.binary_accuracy])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7a229f228d78635a515dd62c164f6fb28dfc8ac1"
      },
      "cell_type": "code",
      "source": "# Validation set\nx_val = x_train[:10000]\npartial_x_train = x_train[10000:]\n\ny_val = y_train[:10000]\npartial_y_train = y_train[10000:]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9755af7cb13cda8c76d2ee3475bf411964323ad8"
      },
      "cell_type": "code",
      "source": "# Training model\nhistory = model.fit(partial_x_train,\n                   partial_y_train,\n                   epochs=20,\n                   batch_size=512,\n                   validation_data=(x_val, y_val))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1a72ae2c7bc296edd561a2724e532e74054b3b18"
      },
      "cell_type": "code",
      "source": "history_dict = history.history\nprint(history_dict.keys())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a7073fed0b1fce6ff683232050744bad89829e4"
      },
      "cell_type": "code",
      "source": "# print evolution of loss\nhistory_dict = history.history\nacc_values = history_dict['binary_accuracy']\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\n\nepochs = range(1, len(acc_values) + 1)\n\nplt.plot(epochs, loss_values, 'bo', label='Training loss')\nplt.plot(epochs, val_loss_values, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3fc032ab25c91079f2496636ef9cd3b9bb34caed"
      },
      "cell_type": "code",
      "source": "# print evolution of accuracy\nplt.clf()\nacc_values = history_dict['binary_accuracy']\nval_acc_values = history_dict['val_binary_accuracy']\n\nplt.plot(epochs, acc_values, 'bo', label='Training acc')\nplt.plot(epochs, val_acc_values, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "475a9d3122afd9442acbb3387fa4c36f8539ee26"
      },
      "cell_type": "code",
      "source": "# New model\nmodel2 = models.Sequential()\nmodel2.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\nmodel2.add(layers.Dense(16, activation='relu'))\nmodel2.add(layers.Dense(1, activation='sigmoid'))\n\nmodel2.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nmodel2.fit(x_train, y_train, epochs=4, batch_size=512)\nresults = model2.evaluate(x_test, y_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2ea0850440539fc47d2a5d7da0193f883fc0a303"
      },
      "cell_type": "code",
      "source": "print(results)\nprint(model2.predict(x_test))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "198e521dd23da2e912740c20d6c99f2f56e12a31"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}